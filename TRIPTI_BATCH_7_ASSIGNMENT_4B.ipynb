{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TRIPTI_BATCH_7_ASSIGNMENT_4B.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/TRIPTIRATHI/Assignment-4/blob/master/TRIPTI_BATCH_7_ASSIGNMENT_4B.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "341cb0da-54e4-4544-edba-54fee08c7b5a"
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 90\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 12\n",
        "num_filter = 72\n",
        "compression = 0.5\n",
        "dropout_rate = 0.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f325906b-0577-4cc3-b557-38a7d4346ccd"
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "147595264/170498071 [========================>.....] - ETA: 6s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096/170498071 [==============================] - 47s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 72, dropout_rate = 0.3):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 60, dropout_rate = 0.3):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AveragePooling =AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AveragePooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_filter = 60\n",
        "dropout_rate = 0.3\n",
        "l = 12\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "\n",
        "Last_Block = add_denseblock(Second_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7446
        },
        "outputId": "edb6bbcc-e86c-4b60-cf13-4118ea8abcc9"
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 32, 32, 60)   1620        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 32, 32, 60)   240         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 32, 32, 60)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 32, 32, 30)   16200       activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_103 (Dropout)           (None, 32, 32, 30)   0           conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_97 (Concatenate)    (None, 32, 32, 90)   0           conv2d_105[0][0]                 \n",
            "                                                                 dropout_103[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 32, 32, 90)   360         concatenate_97[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 32, 32, 90)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 32, 32, 30)   24300       activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_104 (Dropout)           (None, 32, 32, 30)   0           conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_98 (Concatenate)    (None, 32, 32, 120)  0           concatenate_97[0][0]             \n",
            "                                                                 dropout_104[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 32, 32, 120)  480         concatenate_98[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 32, 32, 120)  0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 32, 32, 30)   32400       activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_105 (Dropout)           (None, 32, 32, 30)   0           conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_99 (Concatenate)    (None, 32, 32, 150)  0           concatenate_98[0][0]             \n",
            "                                                                 dropout_105[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 32, 32, 150)  600         concatenate_99[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 32, 32, 150)  0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 32, 32, 30)   40500       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_106 (Dropout)           (None, 32, 32, 30)   0           conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_100 (Concatenate)   (None, 32, 32, 180)  0           concatenate_99[0][0]             \n",
            "                                                                 dropout_106[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 32, 32, 180)  720         concatenate_100[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 32, 32, 180)  0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 32, 32, 30)   48600       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_107 (Dropout)           (None, 32, 32, 30)   0           conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_101 (Concatenate)   (None, 32, 32, 210)  0           concatenate_100[0][0]            \n",
            "                                                                 dropout_107[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 32, 32, 210)  840         concatenate_101[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 32, 32, 210)  0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 32, 32, 30)   56700       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_108 (Dropout)           (None, 32, 32, 30)   0           conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_102 (Concatenate)   (None, 32, 32, 240)  0           concatenate_101[0][0]            \n",
            "                                                                 dropout_108[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 32, 32, 240)  960         concatenate_102[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 32, 32, 240)  0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 32, 32, 30)   64800       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_109 (Dropout)           (None, 32, 32, 30)   0           conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_103 (Concatenate)   (None, 32, 32, 270)  0           concatenate_102[0][0]            \n",
            "                                                                 dropout_109[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 32, 32, 270)  1080        concatenate_103[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 32, 32, 270)  0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 32, 32, 30)   72900       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_110 (Dropout)           (None, 32, 32, 30)   0           conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_104 (Concatenate)   (None, 32, 32, 300)  0           concatenate_103[0][0]            \n",
            "                                                                 dropout_110[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 32, 32, 300)  1200        concatenate_104[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 32, 32, 300)  0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 32, 32, 30)   81000       activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_111 (Dropout)           (None, 32, 32, 30)   0           conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_105 (Concatenate)   (None, 32, 32, 330)  0           concatenate_104[0][0]            \n",
            "                                                                 dropout_111[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 32, 32, 330)  1320        concatenate_105[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 32, 32, 330)  0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 32, 32, 30)   89100       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_112 (Dropout)           (None, 32, 32, 30)   0           conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_106 (Concatenate)   (None, 32, 32, 360)  0           concatenate_105[0][0]            \n",
            "                                                                 dropout_112[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 32, 32, 360)  1440        concatenate_106[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 32, 32, 360)  0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 32, 32, 30)   97200       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_113 (Dropout)           (None, 32, 32, 30)   0           conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_107 (Concatenate)   (None, 32, 32, 390)  0           concatenate_106[0][0]            \n",
            "                                                                 dropout_113[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 32, 32, 390)  1560        concatenate_107[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 32, 32, 390)  0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 32, 32, 30)   105300      activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_114 (Dropout)           (None, 32, 32, 30)   0           conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_108 (Concatenate)   (None, 32, 32, 420)  0           concatenate_107[0][0]            \n",
            "                                                                 dropout_114[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 32, 32, 420)  1680        concatenate_108[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 32, 32, 420)  0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 32, 32, 30)   12600       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_115 (Dropout)           (None, 32, 32, 30)   0           conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 16, 16, 30)   0           dropout_115[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 30)   120         average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 16, 16, 30)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 30)   8100        activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_116 (Dropout)           (None, 16, 16, 30)   0           conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_109 (Concatenate)   (None, 16, 16, 60)   0           average_pooling2d_7[0][0]        \n",
            "                                                                 dropout_116[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 60)   240         concatenate_109[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 60)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 16, 16, 30)   16200       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_117 (Dropout)           (None, 16, 16, 30)   0           conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_110 (Concatenate)   (None, 16, 16, 90)   0           concatenate_109[0][0]            \n",
            "                                                                 dropout_117[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 90)   360         concatenate_110[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 90)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 30)   24300       activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_118 (Dropout)           (None, 16, 16, 30)   0           conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_111 (Concatenate)   (None, 16, 16, 120)  0           concatenate_110[0][0]            \n",
            "                                                                 dropout_118[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 16, 16, 120)  480         concatenate_111[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 16, 16, 120)  0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 30)   32400       activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_119 (Dropout)           (None, 16, 16, 30)   0           conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_112 (Concatenate)   (None, 16, 16, 150)  0           concatenate_111[0][0]            \n",
            "                                                                 dropout_119[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 150)  600         concatenate_112[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 150)  0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 16, 16, 30)   40500       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_120 (Dropout)           (None, 16, 16, 30)   0           conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_113 (Concatenate)   (None, 16, 16, 180)  0           concatenate_112[0][0]            \n",
            "                                                                 dropout_120[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 180)  720         concatenate_113[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 180)  0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 16, 16, 30)   48600       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_121 (Dropout)           (None, 16, 16, 30)   0           conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_114 (Concatenate)   (None, 16, 16, 210)  0           concatenate_113[0][0]            \n",
            "                                                                 dropout_121[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 16, 16, 210)  840         concatenate_114[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 16, 16, 210)  0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 16, 16, 30)   56700       activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_122 (Dropout)           (None, 16, 16, 30)   0           conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_115 (Concatenate)   (None, 16, 16, 240)  0           concatenate_114[0][0]            \n",
            "                                                                 dropout_122[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 16, 16, 240)  960         concatenate_115[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 16, 16, 240)  0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 16, 16, 30)   64800       activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_123 (Dropout)           (None, 16, 16, 30)   0           conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_116 (Concatenate)   (None, 16, 16, 270)  0           concatenate_115[0][0]            \n",
            "                                                                 dropout_123[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 16, 16, 270)  1080        concatenate_116[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 16, 16, 270)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 16, 16, 30)   72900       activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_124 (Dropout)           (None, 16, 16, 30)   0           conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_117 (Concatenate)   (None, 16, 16, 300)  0           concatenate_116[0][0]            \n",
            "                                                                 dropout_124[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 16, 16, 300)  1200        concatenate_117[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 16, 16, 300)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 16, 16, 30)   81000       activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_125 (Dropout)           (None, 16, 16, 30)   0           conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_118 (Concatenate)   (None, 16, 16, 330)  0           concatenate_117[0][0]            \n",
            "                                                                 dropout_125[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 16, 16, 330)  1320        concatenate_118[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 16, 16, 330)  0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 16, 16, 30)   89100       activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_126 (Dropout)           (None, 16, 16, 30)   0           conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_119 (Concatenate)   (None, 16, 16, 360)  0           concatenate_118[0][0]            \n",
            "                                                                 dropout_126[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 16, 16, 360)  1440        concatenate_119[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 16, 16, 360)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 16, 16, 30)   97200       activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_127 (Dropout)           (None, 16, 16, 30)   0           conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_120 (Concatenate)   (None, 16, 16, 390)  0           concatenate_119[0][0]            \n",
            "                                                                 dropout_127[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 16, 16, 390)  1560        concatenate_120[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 16, 16, 390)  0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 16, 16, 30)   11700       activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_128 (Dropout)           (None, 16, 16, 30)   0           conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 30)     0           dropout_128[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 8, 8, 30)     120         average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 8, 8, 30)     0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 8, 8, 30)     8100        activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_129 (Dropout)           (None, 8, 8, 30)     0           conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_121 (Concatenate)   (None, 8, 8, 60)     0           average_pooling2d_8[0][0]        \n",
            "                                                                 dropout_129[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 8, 8, 60)     240         concatenate_121[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 8, 8, 60)     0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 8, 8, 30)     16200       activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_130 (Dropout)           (None, 8, 8, 30)     0           conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_122 (Concatenate)   (None, 8, 8, 90)     0           concatenate_121[0][0]            \n",
            "                                                                 dropout_130[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 8, 8, 90)     360         concatenate_122[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 8, 8, 90)     0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 8, 8, 30)     24300       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_131 (Dropout)           (None, 8, 8, 30)     0           conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_123 (Concatenate)   (None, 8, 8, 120)    0           concatenate_122[0][0]            \n",
            "                                                                 dropout_131[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 8, 8, 120)    480         concatenate_123[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 8, 8, 120)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 8, 8, 30)     32400       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_132 (Dropout)           (None, 8, 8, 30)     0           conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_124 (Concatenate)   (None, 8, 8, 150)    0           concatenate_123[0][0]            \n",
            "                                                                 dropout_132[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 8, 8, 150)    600         concatenate_124[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 8, 8, 150)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 8, 8, 30)     40500       activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_133 (Dropout)           (None, 8, 8, 30)     0           conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_125 (Concatenate)   (None, 8, 8, 180)    0           concatenate_124[0][0]            \n",
            "                                                                 dropout_133[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 8, 8, 180)    720         concatenate_125[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 8, 8, 180)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 8, 8, 30)     48600       activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_134 (Dropout)           (None, 8, 8, 30)     0           conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_126 (Concatenate)   (None, 8, 8, 210)    0           concatenate_125[0][0]            \n",
            "                                                                 dropout_134[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 8, 8, 210)    840         concatenate_126[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 8, 8, 210)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 8, 8, 30)     56700       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_135 (Dropout)           (None, 8, 8, 30)     0           conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_127 (Concatenate)   (None, 8, 8, 240)    0           concatenate_126[0][0]            \n",
            "                                                                 dropout_135[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 8, 8, 240)    960         concatenate_127[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 8, 8, 240)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 8, 8, 30)     64800       activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_136 (Dropout)           (None, 8, 8, 30)     0           conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_128 (Concatenate)   (None, 8, 8, 270)    0           concatenate_127[0][0]            \n",
            "                                                                 dropout_136[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 8, 8, 270)    1080        concatenate_128[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 8, 8, 270)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 8, 8, 30)     72900       activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_137 (Dropout)           (None, 8, 8, 30)     0           conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_129 (Concatenate)   (None, 8, 8, 300)    0           concatenate_128[0][0]            \n",
            "                                                                 dropout_137[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 8, 8, 300)    1200        concatenate_129[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 8, 8, 300)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 8, 8, 30)     81000       activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_138 (Dropout)           (None, 8, 8, 30)     0           conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_130 (Concatenate)   (None, 8, 8, 330)    0           concatenate_129[0][0]            \n",
            "                                                                 dropout_138[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 8, 8, 330)    1320        concatenate_130[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 8, 8, 330)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 8, 8, 30)     89100       activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_139 (Dropout)           (None, 8, 8, 30)     0           conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_131 (Concatenate)   (None, 8, 8, 360)    0           concatenate_130[0][0]            \n",
            "                                                                 dropout_139[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 8, 8, 360)    1440        concatenate_131[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 8, 8, 360)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 8, 8, 30)     97200       activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_140 (Dropout)           (None, 8, 8, 30)     0           conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_132 (Concatenate)   (None, 8, 8, 390)    0           concatenate_131[0][0]            \n",
            "                                                                 dropout_140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 8, 8, 390)    1560        concatenate_132[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 8, 8, 390)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 4, 4, 390)    0           activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 6240)         0           average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           62410       flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,115,250\n",
            "Trainable params: 2,098,090\n",
            "Non-trainable params: 17,160\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f4f9sn3AWGPJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# checkpoint\n",
        "filepath=\"wh.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "callbacks_list = [checkpoint, reduce_lr]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3964
        },
        "outputId": "3f4e7f65-a86f-450c-e3ed-a1f4b954063b"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks_list,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 503s 10ms/step - loss: 1.4451 - acc: 0.4863 - val_loss: 2.2892 - val_acc: 0.4235\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.42350, saving model to wh.best.hdf5\n",
            "Epoch 2/50\n",
            " 4410/50000 [=>............................] - ETA: 6:52 - loss: 1.0755 - acc: 0.6249"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.9722 - acc: 0.6568 - val_loss: 1.5935 - val_acc: 0.5700\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.42350 to 0.57000, saving model to wh.best.hdf5\n",
            "Epoch 3/50\n",
            "16380/50000 [========>.....................] - ETA: 5:03 - loss: 0.8021 - acc: 0.7178"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.7755 - acc: 0.7275 - val_loss: 1.0686 - val_acc: 0.6855\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.57000 to 0.68550, saving model to wh.best.hdf5\n",
            "Epoch 4/50\n",
            "19710/50000 [==========>...................] - ETA: 4:33 - loss: 0.6657 - acc: 0.7669"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.6616 - acc: 0.7688 - val_loss: 1.0376 - val_acc: 0.7056\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.68550 to 0.70560, saving model to wh.best.hdf5\n",
            "Epoch 5/50\n",
            "20610/50000 [===========>..................] - ETA: 4:25 - loss: 0.5902 - acc: 0.7920"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.5788 - acc: 0.7963 - val_loss: 0.8829 - val_acc: 0.7386\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.70560 to 0.73860, saving model to wh.best.hdf5\n",
            "Epoch 6/50\n",
            "20880/50000 [===========>..................] - ETA: 4:22 - loss: 0.5239 - acc: 0.8164"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.5256 - acc: 0.8167 - val_loss: 1.2653 - val_acc: 0.6672\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.73860\n",
            "Epoch 7/50\n",
            "23580/50000 [=============>................] - ETA: 3:58 - loss: 0.4725 - acc: 0.8357"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.4749 - acc: 0.8329 - val_loss: 0.7826 - val_acc: 0.7688\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.73860 to 0.76880, saving model to wh.best.hdf5\n",
            "Epoch 8/50\n",
            "21690/50000 [============>.................] - ETA: 4:15 - loss: 0.4288 - acc: 0.8482"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.4317 - acc: 0.8497 - val_loss: 0.6298 - val_acc: 0.8096\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.76880 to 0.80960, saving model to wh.best.hdf5\n",
            "Epoch 9/50\n",
            "21150/50000 [===========>..................] - ETA: 4:19 - loss: 0.3805 - acc: 0.8675"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.3917 - acc: 0.8635 - val_loss: 1.0461 - val_acc: 0.7309\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80960\n",
            "Epoch 10/50\n",
            "23580/50000 [=============>................] - ETA: 3:58 - loss: 0.3571 - acc: 0.8745"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.3643 - acc: 0.8728 - val_loss: 0.6159 - val_acc: 0.8172\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.80960 to 0.81720, saving model to wh.best.hdf5\n",
            "Epoch 11/50\n",
            "21600/50000 [===========>..................] - ETA: 4:15 - loss: 0.3389 - acc: 0.8829"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.3388 - acc: 0.8826 - val_loss: 0.7391 - val_acc: 0.8007\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.81720\n",
            "Epoch 12/50\n",
            "23760/50000 [=============>................] - ETA: 3:56 - loss: 0.3076 - acc: 0.8925"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.3134 - acc: 0.8904 - val_loss: 1.4741 - val_acc: 0.6901\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.81720\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 13/50\n",
            "18720/50000 [==========>...................] - ETA: 4:41 - loss: 0.2253 - acc: 0.9240"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.2102 - acc: 0.9278 - val_loss: 0.4742 - val_acc: 0.8692\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.81720 to 0.86920, saving model to wh.best.hdf5\n",
            "Epoch 14/50\n",
            "20250/50000 [===========>..................] - ETA: 4:28 - loss: 0.1848 - acc: 0.9369"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.1830 - acc: 0.9379 - val_loss: 0.4788 - val_acc: 0.8695\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.86920 to 0.86950, saving model to wh.best.hdf5\n",
            "Epoch 15/50\n",
            "20700/50000 [===========>..................] - ETA: 4:23 - loss: 0.1697 - acc: 0.9428"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 485s 10ms/step - loss: 0.1712 - acc: 0.9419 - val_loss: 0.4759 - val_acc: 0.8717\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.86950 to 0.87170, saving model to wh.best.hdf5\n",
            "Epoch 16/50\n",
            "20790/50000 [===========>..................] - ETA: 4:23 - loss: 0.1631 - acc: 0.9450"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.1649 - acc: 0.9441 - val_loss: 0.4881 - val_acc: 0.8668\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.87170\n",
            "Epoch 17/50\n",
            "23490/50000 [=============>................] - ETA: 3:58 - loss: 0.1553 - acc: 0.9459"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.1577 - acc: 0.9458 - val_loss: 0.4925 - val_acc: 0.8668\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.87170\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 18/50\n",
            "18720/50000 [==========>...................] - ETA: 4:41 - loss: 0.1470 - acc: 0.9496"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 485s 10ms/step - loss: 0.1445 - acc: 0.9515 - val_loss: 0.4664 - val_acc: 0.8727\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.87170 to 0.87270, saving model to wh.best.hdf5\n",
            "Epoch 19/50\n",
            "20250/50000 [===========>..................] - ETA: 4:27 - loss: 0.1427 - acc: 0.9535"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 485s 10ms/step - loss: 0.1437 - acc: 0.9517 - val_loss: 0.4805 - val_acc: 0.8718\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.87270\n",
            "Epoch 20/50\n",
            "23310/50000 [============>.................] - ETA: 4:00 - loss: 0.1421 - acc: 0.9519"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 485s 10ms/step - loss: 0.1412 - acc: 0.9523 - val_loss: 0.4735 - val_acc: 0.8722\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.87270\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Epoch 21/50\n",
            "18630/50000 [==========>...................] - ETA: 4:42 - loss: 0.1374 - acc: 0.9538"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.1379 - acc: 0.9536 - val_loss: 0.4712 - val_acc: 0.8724\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.87270\n",
            "Epoch 22/50\n",
            "22770/50000 [============>.................] - ETA: 4:05 - loss: 0.1391 - acc: 0.9528"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.1376 - acc: 0.9534 - val_loss: 0.4716 - val_acc: 0.8726\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.87270\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "Epoch 23/50\n",
            "18540/50000 [==========>...................] - ETA: 4:43 - loss: 0.1405 - acc: 0.9549"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.1386 - acc: 0.9545 - val_loss: 0.4685 - val_acc: 0.8726\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.87270\n",
            "Epoch 24/50\n",
            "22770/50000 [============>.................] - ETA: 4:05 - loss: 0.1391 - acc: 0.9538"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1370 - acc: 0.9546 - val_loss: 0.4729 - val_acc: 0.8719\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.87270\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "Epoch 25/50\n",
            "18630/50000 [==========>...................] - ETA: 4:43 - loss: 0.1360 - acc: 0.9564"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1360 - acc: 0.9554 - val_loss: 0.4709 - val_acc: 0.8726\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.87270\n",
            "Epoch 26/50\n",
            "22770/50000 [============>.................] - ETA: 4:05 - loss: 0.1388 - acc: 0.9532"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.1370 - acc: 0.9542 - val_loss: 0.4731 - val_acc: 0.8720\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.87270\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
            "Epoch 27/50\n",
            "18630/50000 [==========>...................] - ETA: 4:43 - loss: 0.1372 - acc: 0.9537"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.1384 - acc: 0.9546 - val_loss: 0.4714 - val_acc: 0.8726\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.87270\n",
            "Epoch 28/50\n",
            "22770/50000 [============>.................] - ETA: 4:05 - loss: 0.1393 - acc: 0.9535"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 486s 10ms/step - loss: 0.1394 - acc: 0.9531 - val_loss: 0.4719 - val_acc: 0.8725\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.87270\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
            "Epoch 29/50\n",
            "18630/50000 [==========>...................] - ETA: 4:43 - loss: 0.1415 - acc: 0.9513"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1393 - acc: 0.9534 - val_loss: 0.4700 - val_acc: 0.8727\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.87270\n",
            "Epoch 30/50\n",
            "22860/50000 [============>.................] - ETA: 4:05 - loss: 0.1376 - acc: 0.9561"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1394 - acc: 0.9543 - val_loss: 0.4692 - val_acc: 0.8732\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.87270 to 0.87320, saving model to wh.best.hdf5\n",
            "Epoch 31/50\n",
            "21420/50000 [===========>..................] - ETA: 4:18 - loss: 0.1377 - acc: 0.9536"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1392 - acc: 0.9528 - val_loss: 0.4721 - val_acc: 0.8727\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.87320\n",
            "Epoch 32/50\n",
            "23670/50000 [=============>................] - ETA: 3:58 - loss: 0.1386 - acc: 0.9541"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1376 - acc: 0.9544 - val_loss: 0.4695 - val_acc: 0.8727\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.87320\n",
            "\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
            "Epoch 33/50\n",
            "18810/50000 [==========>...................] - ETA: 4:41 - loss: 0.1403 - acc: 0.9534"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1389 - acc: 0.9537 - val_loss: 0.4717 - val_acc: 0.8725\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.87320\n",
            "Epoch 34/50\n",
            "22860/50000 [============>.................] - ETA: 4:05 - loss: 0.1373 - acc: 0.9554"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1386 - acc: 0.9545 - val_loss: 0.4710 - val_acc: 0.8728\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.87320\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
            "Epoch 35/50\n",
            "18630/50000 [==========>...................] - ETA: 4:43 - loss: 0.1376 - acc: 0.9544"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1377 - acc: 0.9539 - val_loss: 0.4720 - val_acc: 0.8722\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.87320\n",
            "Epoch 36/50\n",
            "22770/50000 [============>.................] - ETA: 4:06 - loss: 0.1414 - acc: 0.9530"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1390 - acc: 0.9534 - val_loss: 0.4717 - val_acc: 0.8725\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.87320\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
            "Epoch 37/50\n",
            "18540/50000 [==========>...................] - ETA: 4:44 - loss: 0.1427 - acc: 0.9525"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1378 - acc: 0.9544 - val_loss: 0.4725 - val_acc: 0.8726\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.87320\n",
            "Epoch 38/50\n",
            "22770/50000 [============>.................] - ETA: 4:05 - loss: 0.1388 - acc: 0.9534"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1381 - acc: 0.9538 - val_loss: 0.4712 - val_acc: 0.8723\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.87320\n",
            "\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
            "Epoch 39/50\n",
            "18540/50000 [==========>...................] - ETA: 4:44 - loss: 0.1393 - acc: 0.9542"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1380 - acc: 0.9547 - val_loss: 0.4710 - val_acc: 0.8728\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.87320\n",
            "Epoch 40/50\n",
            "22770/50000 [============>.................] - ETA: 4:06 - loss: 0.1399 - acc: 0.9530"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1401 - acc: 0.9531 - val_loss: 0.4689 - val_acc: 0.8730\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.87320\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
            "Epoch 41/50\n",
            "18540/50000 [==========>...................] - ETA: 4:44 - loss: 0.1382 - acc: 0.9545"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1377 - acc: 0.9552 - val_loss: 0.4714 - val_acc: 0.8726\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.87320\n",
            "Epoch 42/50\n",
            "22770/50000 [============>.................] - ETA: 4:05 - loss: 0.1347 - acc: 0.9556"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1356 - acc: 0.9555 - val_loss: 0.4711 - val_acc: 0.8729\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.87320\n",
            "\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
            "Epoch 43/50\n",
            "18540/50000 [==========>...................] - ETA: 4:44 - loss: 0.1338 - acc: 0.9566"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1381 - acc: 0.9541 - val_loss: 0.4700 - val_acc: 0.8727\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.87320\n",
            "Epoch 44/50\n",
            "22770/50000 [============>.................] - ETA: 4:06 - loss: 0.1377 - acc: 0.9527"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1371 - acc: 0.9532 - val_loss: 0.4710 - val_acc: 0.8731\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.87320\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
            "Epoch 45/50\n",
            "18540/50000 [==========>...................] - ETA: 4:44 - loss: 0.1397 - acc: 0.9533"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1374 - acc: 0.9539 - val_loss: 0.4721 - val_acc: 0.8725\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.87320\n",
            "Epoch 46/50\n",
            "22770/50000 [============>.................] - ETA: 4:05 - loss: 0.1394 - acc: 0.9528"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1396 - acc: 0.9532 - val_loss: 0.4736 - val_acc: 0.8720\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.87320\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
            "Epoch 47/50\n",
            "18540/50000 [==========>...................] - ETA: 4:43 - loss: 0.1374 - acc: 0.9544"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1383 - acc: 0.9546 - val_loss: 0.4736 - val_acc: 0.8720\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.87320\n",
            "Epoch 48/50\n",
            "22770/50000 [============>.................] - ETA: 4:05 - loss: 0.1379 - acc: 0.9553"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1379 - acc: 0.9549 - val_loss: 0.4712 - val_acc: 0.8725\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.87320\n",
            "\n",
            "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
            "Epoch 49/50\n",
            "18630/50000 [==========>...................] - ETA: 4:43 - loss: 0.1354 - acc: 0.9554"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 487s 10ms/step - loss: 0.1386 - acc: 0.9529 - val_loss: 0.4718 - val_acc: 0.8724\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.87320\n",
            "Epoch 50/50\n",
            "22770/50000 [============>.................] - ETA: 4:05 - loss: 0.1384 - acc: 0.9540"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49770/50000 [============================>.] - ETA: 2s - loss: 0.1412 - acc: 0.9527"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "eca19830-2ee8-4124-e48a-840c4fc8cf3d"
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 41s 4ms/step\n",
            "Test loss: 0.47160090514421465\n",
            "Test accuracy: 0.8728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UE3lF6EH1r_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7b5144e-b8e3-4607-c63a-eefb2a40ea4e"
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ai-yZ2ED5AK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Og56VCRh5j8V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}